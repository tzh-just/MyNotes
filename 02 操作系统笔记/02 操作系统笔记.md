# 硬件结构
## 内存
内存的地址是从 0 开始编号的，然后⾃增排列，最后⼀个地址为内存总字节数 - 1，这种结构好似我们程序 ⾥的数组，所以内存的读写任何⼀个数据的速度都是⼀样的。
## CPU
CPU 位宽越⼤，可以计算的数值就越⼤
CPU 内部还有⼀些组件，常⻅的有寄存器、控制单元和逻辑运算单元等。
CPU 中的寄存器主要作⽤是存储计算时的数据，
因为内存离 CPU 太远了，⽽寄存器就在 CPU ⾥，还紧挨着控制单元和逻辑运算单元，计算速度会更快
### 寄存器
- 通⽤寄存器，⽤来存放需要进⾏运算的数据，⽐如需要进⾏加和运算的两个数据。
- 程序计数器，⽤来存储 CPU 要执⾏下⼀条指令「所在的内存地址」，注意不是存储了下⼀条要执⾏ 的指令，此时指令还在内存中，程序计数器只是存储了下⼀条指令的地址。
- 指令寄存器，⽤来存放程序计数器指向的指令，也就是指令本身，指令被执⾏完成之前，指令都存储 在这⾥。
### 总线
- 地址总线，⽤于指定 CPU 将要操作的内存地址；
- 数据总线，⽤于读写内存的数据；
- 控制总线，⽤于发送和接收信号，⽐如中断、设备复位等信号，CPU 收到信号后⾃然进⾏响应，这时也需要控制总线；

当 CPU 要读写内存数据：
- ⾸先要通过「地址总线」来指定内存的地址；
- 再通过「数据总线」来传输数据；

### 输入输出设备
输⼊设备向计算机输⼊数据，计算机经过计算后，把数据输出给输出设备。
如果输⼊设备是键盘，按下按键时是需要和 CPU 进⾏交互的，这时就需要⽤到控制总线了。

### 线路位宽与CPU位宽
低电压表示 0，⾼压电压则表示 1。
如果只有⼀条线路，就意味着每次只能传递 1 bit 的数据，即 0 或 1。这样⼀位⼀位传输的⽅式，称为串⾏。
线路的位宽最好⼀次就能访问到所有的内存地址。如果想要 CPU 操作 4G 的内存，那么就需要 32 条地址总线，因为 2 ^ 32 =4G 。

### 程序执⾏的基本过程
⼀个程序执⾏的时候，CPU 会根据程序计数器⾥的内存地址，从内存⾥⾯把需要执⾏的指令读取到指令寄存器⾥⾯执⾏，然后根据指令⻓度⾃增，开始顺序读取下⼀条指令。
1. CPU 读取「程序计数器」的值，这个值是指令的内存地址，这个部分称为 Fetch（取得指令）
	1. CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址
	2. 通知内存设备准备数据，数据准备好后通过「数据总线」将指令数据传给 CPU
	3. CPU 收到内存传来的数据后，将这个指令数据存⼊到「指令寄存器」
2. CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，这个部分称为 Decode（指令译码）
	1. 如果是计算类型的指令，就把指令交给「逻辑运算单元」运算
	2. 如果是存储类型的指令，则交由「控制单元」执⾏
	3. 
3. CPU Execution（执⾏指令）后，「程序计数器」的值⾃增，表示指向下⼀条指令。
	1. ⾃增的⼤⼩由CPU 的位宽决定
	2. CPU 将计算结果存回寄存器或者将寄存器的值存⼊内存，这个部分称为 Store（数据回写）
CPU 从程序计数器读取指令、到执⾏、再到下⼀条指令，这个过程会不断循环，直到程序执⾏结束，这个不断循环的过程被称为 CPU 的指令周期。

### a = 1 + 2 执⾏具体过程
编译器通过分析代码，发现 1 和 2 是数据，于是程序运⾏时，内存会有个专⻔的区域来存放这些数据，这个区域就是「数据段」。注意，数据和指令是分开区域存放的，存放指令区域的地⽅称为「正⽂段」。
例如编译完成后，具体执⾏程序的时候，程序计数器会被设置为 0x200 地址，然后依次执⾏这 4 条指令。
- 0x200 的内容是 load 指令将 0x100 地址中的数据 1 装⼊到寄存器 R0
- 0x204 的内容是 load 指令将 0x104 地址中的数据 2 装⼊到寄存器 R1
- 0x208 的内容是 add 指令将寄存器 R0 和 R1 的数据相加，并把结果存放到寄存器 R2
- 0x20c 的内容是 store 指令将寄存器 R2 中的数据存回数据段中的 0x108 地址中，这个地址也就是变量 a 内存中的地址

事实上指令的内容是⼀串⼆进制数字的机器码，每条指令都有对应的机器码，CPU 通过解析机器码来知道指令的内容。
十六进制add指令0x00011020
- add 对应的 MIPS 指令⾥操作码是 000000 ，以及最末尾的功能码是 100000
- rs 代表第⼀个寄存器 R0 的编号，即 00000
- rt 代表第⼆个寄存器 R1 的编号，即 00001
- rd 代表⽬标的临时寄存器 R2 的编号，即 00010
- 因为不是位移操作，所以位移量是 00000
| 指令 | 指令类型 | 操作码6位 | rs5位 | rt五位 | rd5位 | 位移量5位 | 功能码6位 |
| ---- | -------- | --------- | ----- | ------ | ----- | --------- | --------- |
| add  | R        | 000000    | 00000 | 00001  | 00010 | 00000     | 100000          |

指令存放在存储器中，由控制器通过程序计数器和指令寄存器取出指令后译码为不同的操作信号、地址和操作数，操作如果是算数、逻辑、数据传输、条件分支都是算数逻辑单元操作，即运算器。如果是简单的无条件地址跳转则由控制器自己完成。


指令类型
- 数据传输类型的指令，store/load 是寄存器与内存间数据传输的指令， mov 是将⼀个内存地址的数据移动到另⼀个内存地址的指令
- 运算类型的指令，如加减乘除、位运算、⽐较⼤⼩等等，最多只能处理两个寄存器中的数据
- 跳转类型的指令，通过修改程序计数器的值来达到跳转执⾏指令的过程，如 if-else 、 swtich-case、函数调⽤等
- 信号类型的指令，⽐如发⽣中断的指令 trap
- 闲置类型的指令，⽐如指令 nop ，执⾏后 CPU 会空转⼀个周期
### 总结
>64 位相⽐ 32 位 CPU 的优势在哪吗？64 位 CPU 的计算性能⼀定⽐ 32 位 CPU ⾼很多吗？

64 位 CPU 可以⼀次计算超过 32 位的数字，⽽ 32 位 CPU 如果要计算超过 32 位的数字，要分多步骤进⾏计算，效率就没那么⾼。只有运算⼤数字的时候，64 位 CPU 的优势才能体现出来，否则和 32 位 CPU 的计算性能相差不⼤。

>软件的 32 位和 64 位之间的区别？32 位的操作系统可以运⾏在 64 位的电脑上吗？64 位的操作系统可以运⾏在 32 位的电脑上吗？

64 位和 32 位软件，实际上代表指令是 64 位还是 32 位的。如果 32 位指令在 64 位机器上执⾏，需要⼀套兼容机制，就可以做到兼容运⾏了。如果 64 位指令在 32 位机器上执⾏，就⽐较困难了，因为 32 位的寄存器存不下 64 位的指令。64 位操作系统，指令也就是 64 位，因此不能装在 32 位机器上。

## 存储器金字塔
CPU 中的寄存器，处理速度是最快的，但是能存储的数据也是最少的。
CPU Cache 通常会分为 L1、L2、L3 三层，其中 L1 Cache 通常分成「数据缓存」和「指令缓存」，L1是距离 CPU 最近的，因此它⽐ L2、L3 的读写速度都快、存储空间都⼩。
| 存储器 | 分布                         | 速度                    | 大小        |
| ------ | ---------------------------- | ----------------------- | ----------- |
| 寄存器 | ⼏⼗到⼏百个                 | 半个 CPU 时钟周期       | 根据CPU位宽 |
| L1     | 每个核心各一个数据和指令缓存 | 2~4时钟周期             | 几十KB      |
| L2     | 每个核心一块                 | 10~20 个时钟周期        | ⼏百 KB     |
| L3     | 核心共享                     | 20~60 个时钟周期        | 几MB        |
| 内存   |                              | 200~300 个 时钟周期之间 |             |
| SSD       |                |       内存的10到1000分之一              |             |

![](Pasted%20image%2020230718101725.png)

CPU 需要访问内存中某个数据时，会从寄存器沿着金字塔往下查询。程序执行时，会将内存中的数据加载到共享的 L3 Cache 中，再加载到每个核⼼独有的 L2 Cache，最后进⼊到最快的 L1 Cache，之后才会被 CPU 读取。

### Cache Line
CPU Cache 的数据是从内存中读取过来的，它是以⼀⼩块⼀⼩块读取数据的，⽽不是按照单个数组元素来读取数据的，在 CPU Cache 中的，这样⼀⼩块⼀⼩块的数据，称为 Cache Line（缓存块）。
以 64 字节的 L1 Cache Line 为例，对于 int array[100] 的数组，当载⼊ array[0] 时，由于这个数组元素的⼤⼩在内存只占 4 字节，不⾜ 64 字节，CPU 就会顺序加载数组元素到 array[15] ， 即0-15的数组元素都被缓存在 CPU Cache 中。当下次访问这些数组元素时，会直接从 CPU Cache 读取，大大地提高了速度访问速度。
注意，⽆论数据是否存放到 Cache 中，CPU 都是先访问 Cache，只有当 Cache中找不到数据时，才会去访问内存，并把内存中的数据读⼊到 Cache 中，CPU 再从 CPU Cache 读取数据。

### Direct Mapped Cache
CPU Cache Line 会存储
- ⼀个组标记（Tag），用于标记不同的内存块
- 从内存加载过来的数据
- 一个有效位，用于标记Cache Line中的数据是否有效
例如CPU有8个Cache Line，内存分为32块，对内存地址进行取模，对于映射到同一Cache Line的内存块，通过标记识别。当有效位为0时，不会读取Cache而是从内存中读取。

CPU读取Cache时不是读取Line的整个数据，而是一个字Word。
因此需要一个偏移量来定位Line中的某个数据片段。

一个内存的访问地址为组标记+索引+偏移量组成。
- 通过内存访问地址中的索引找到对应的CacheLine
- 根据有效位判断是否从Cache中读取数据
- 通过内存访问地址中的组标记判断是否为对应的内存块
- 根据偏移量在数据块中读取对应的字
CPU Cache中的数据结构为
索引+有效位+组标记+数据块组成
![](Pasted%20image%2020230718105452.png)


## Cache Miss 
如果 CPU 所要操作的数据在 CPU Cache 中的话，这样将会带来很⼤的性能提升。
**数据缓存**
例如遍历数组时，如果按照先行后列的方式遍历，在第一次读取array[0]时会将后面若干个元素一起加载到cache，这样在读取后面的元素时速度大大加快。如果按照先列后行的方式遍历，则数组元素的读取是跳跃式的，每次都无法从Cache中读取到。
**指令缓存**
如果分⽀预测可以预测到接下来要执⾏ if ⾥的指令，还是 else 指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU 可以直接从 Cache读取到指令，于是执⾏速度就会很快。
当数组中的元素是随机的，分⽀预测就⽆法有效⼯作，⽽当数组元素都是是顺序的，则会缓存 if ⾥的指令到 Cache 中，后续 CPU 执⾏该指令从 Cache 读取。


## CPU缓存一致性
### 写直达
保持内存与 Cache ⼀致性最简单的⽅式是，把数据同时写⼊内存和 Cache 中，这种⽅法称为写直达
- 如果数据已经在 Cache ⾥⾯，先将数据更新到 Cache ⾥⾯，再写⼊到内存⾥⾯；
- 如果数据没有在 Cache ⾥⾯，就直接把数据更新到内存⾥⾯。
每次写操作都会写回到内存，性能会受到很⼤的影响。
### 写回
在写回机制中，当发⽣写操作时，新的数据仅仅被写⼊ Cache Block ⾥，只有当修改过的 Cache Block「被替换」时才需要写到内存中

- 如果当发⽣写操作时，数据已经在 CPU Cache ⾥的话，则把数据更新到 CPU Cache ⾥。同时标记CPU Cache ⾥的这个 Cache Block 为 dirty，这表示cache中的数据与内存中的不一致，但不需要写回内存。
- 如果当发⽣写操作时，数据所对应的 Cache Block ⾥存放的是「别的内存地址的数据」的话，就需要检查已存在的数据是否是脏的，即是否与内存中的不一致。如果是脏的，就把已存在的数据写回内存，然后再写入新数据。
简单来说，只有cache中的数据发生cache miss时，才需要把未命中的数据写回内存。因此只要我们的数据操作降低cache miss就使得cpu大部分时间里不需要写回内存，提高性能。


### 缓存一致性
由于L1/L2缓存时多个核心独有的，那么会带来多核⼼的缓存⼀致性。
例如A核心的cache缓存i=0，执行i++后还没有写回内存，此时B核心则从内存中读取了变量i，导致CPU核心之间的缓存不一致。
![](Pasted%20image%2020230718164943.png)

- 写传播：某个 CPU 核⼼⾥的 Cache 数据更新时，必须要传播到其他核⼼的 Cache
- 事务串行化：，某个 CPU 核⼼⾥对数据的操作顺序，必须在其他核⼼看起来顺序是⼀样的
	- CPU 核⼼对于 Cache 中数据的操作，需要同步给其他 CPU 核⼼
	- 要引⼊「锁」的概念
- 
总线嗅探
当 A 号 CPU 核⼼修改了 L1 Cache 中 i 变量的值，通过总线把这个事件⼴播通知给其他所有的核⼼。
后每个 CPU 核⼼都会监听总线上的⼴播事件，并检查是否有相同的数据在⾃⼰的 L1 Cache ⾥⾯，如果有则需要更新数据到自己的 L1 Cache。
总线嗅探只保证了某个 CPU 核⼼的 Cache 更新数据这个事件能被其他 CPU 核⼼知道，不能保证事务串形化。每时每刻监听总线上的⼀切活动，不管别的核⼼的 Cache 是否缓存相同的数据都需要发出⼀个⼴播事件，会加重总线的负载。

MESI协议
Modified Exclusive Shared Invalidate
已修改 独占 共享 已失效

已失效状态，表示的是这个 Cache Block ⾥的数据已经失效了，不可以读取该状态的数据。
独占和共享状态都代表 Cache Block ⾥的数据是⼲净的。独占状态代表数据只存储在⼀个 CPU 核⼼的 Cache ⾥，可以直接⾃由地写⼊。如果有其他核⼼从内存读取了相同的数据到各⾃的 Cache ，独占的数据回返回给其他核心，并且变成共享状态。
共享状态代表着相同的数据在多个 CPU 核⼼的 Cache ⾥都有，更新 Cache ⾥⾯的数据的时候，不能直接修改，要先向所有的其他 CPU 核⼼⼴播⼀个请求，把其他核⼼的 Cache 中对应的 Cache Line 标记为⽆效状态，然后才能更新 Cache的数据，同时标记 Cache Line 为已修改
如果继续修改已修改状态的数据，则无需通知其他核心。如果已修改状态的数据要被替换，则会将数据同步到内存中。

## CPU执行任务

### 伪共享
CPU Line 是 CPU 从内存读取数据到 Cache 的单位。对数组的加载， CPU 就会加载数组⾥⾯连续的多个数据到 Cache ⾥，按照物理内存地址分布的顺序去访问元素，Cache 命中率就会很⾼。
不使⽤数组，⽽是使⽤单独的变量的时候，则会有 Cache 伪共享的问题。
当连续数组被不同的核心同时加载同一个Cache Line时，假设线程A绑定了核心A修改变量A，线程B绑定了核心B修改变量B。


![](Pasted%20image%2020230718175229.png)

- 当线程A访问变量A，将Cache Line读取到Cache中，标记独占
- 当线程B访问变量B，变量AB同属于一个Cache Line，也读取到Cahce中，核心1和核心2都更新为共享。
- 核心1修改变量A，发现状态为共享，则通过总线通知核心2将该CacheLine标记为已失效，自己为已修改。
- 核心2修改变量B，发现状态为已失效，核心1有相同数据且为已修改，因此将核心1的cache line写回内存，然后核心2从内存中重新读取cache line 到cache，将修改的B更新到cache中，标记为已修改
如果 1 号和 2 号 CPU 核⼼这样持续交替的分别修改变量 A 和 B，就会重复以上步骤，使得Cache没有起到缓存的作用。
这是因为多个变量同属于一个cache line，多线程下分别修改导致数据需要不断地写回内存。

对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同⼀个 Cache Line 中，否则就会出现为伪共享的问题。

或者通过宏标记变量，使得相邻的两个变量不在同一个cache line中，牺牲一部分空间。


### CPU如何选择线程
在 Linux 内核中，进程和线程都是⽤ tark_struct 结构体表示的
线程的 tark_struct 结构体⾥部分资源是共享了进程已创建的资源，⽐如内存地址空间、代码段、⽂件描述符等。所以 Linux 中的线程也被称为轻量级进程。

没有创建线程的进程，是只有单个执⾏流，它被称为是主线程。

调度类
Deadline 按照 deadline 进⾏调度的，距离当前时间点最近的 deadline 的任务会被优先调度；
Reatime 对于相同优先级的任务，按先来先服务的原则，但是优先级更⾼的任务，可以抢占低优先级的任务，也就是优先级⾼的可以「插队」；
Fair 对于相同优先级的任务，轮流着运⾏，每个任务都有⼀定的时间⽚，当⽤完时间⽚的任务会被放到队列尾部，以保证相同优先级任务的公平性，但是⾼优先级的任务依然可以抢占低优先级的任务；
Fair 调度类是应⽤于普通任务，分为两种调度策略
1. 普通任务使⽤的调度策略；
2. 后台任务的调度策略，不和终端进⾏交互，因此在不影响其他需要交互的任务，可以适当降低它的优先级。
Linux 基于 CFS 的调度算法：完全公平调度
它为每个任务安排⼀个虚拟运⾏时间vruntime，如果⼀个任务在运⾏，其运⾏的越久，该任务的vruntime⾃然就会越⼤，⽽没有被运⾏的任务，vruntime 是不会变化的。在 CFS 算法调度的时候，会优先选择 vruntime 少的任务。
在计算虚拟运⾏时间 vruntime 还要考虑普通任务的权重值，注意权重值并不是优先级的值，内核中会有⼀个 nice 级别与权重值的转换表，nice 级别越低的权重值就越⼤。

虚拟运行时间vruntime+=实际运行时间delta_exec × NICE_0_LOAD / 权重

### CPU 运⾏队列

⼀个系统通常都会运⾏着很多任务，多任务的数量基本都是远超 CPU 核⼼数量，因此这时候就需要排队。
每个 CPU 都有⾃⼰的运⾏队列⽤于描述在此 CPU 上所运⾏的所有进程

其队列包含三个运⾏队列，Deadline 运⾏队列 dl_rq、实时任务运⾏队列 rt_rq 和 CFS 运⾏队列 csf_rq，
其中 csf_rq 是⽤红⿊树来描述的，按 vruntime ⼤⼩来排序的，最左侧的叶⼦节点，就是下次会被调度的任务。
![](Pasted%20image%2020230718182306.png)


优先级如下：Deadline > Realtime > Fair，先从 dl_rq ⾥选择任务，然后从 rt_rq ⾥选择任务，最后从 csf_rq ⾥选择任务。

启动任务的时候，没有特意去指定优先级的话，默认情况下都是普通任务。想让某个普通任务有更多的执⾏时间，可以调整任务的 nice 值。。nice 的值能设置的范围是-20～19。
值越低，表明优先级越⾼。这是因为nice 值并不是表示优先级，⽽是表示优先级的修正数值：priority(new) = priority(old) + nice内核中，priority 的范围是0~139，值越低，优先级越⾼。nice 值调整的是普通任务的优先级。
![](Pasted%20image%2020230718182528.png)


## 软中断
中断是⼀种异步的事件处理机制，可以提⾼系统的并发处理能⼒。
操作系统收到了中断请求，会打断其他进程的运⾏，所以中断请求的响应程序，也就是中断处理程序，要尽可能快的执⾏完，这样可以减少对正常进程运⾏调度地影响。
中断处理程序在响应中断时，可能还会「临时关闭中断」。如果当前中断处理程序没有执⾏完之前，系统中其他的中断请求都⽆法被响应，也就说中断有可能会丢失。

Linux 系统将中断过程分成「上半部和下半部分」
| 中断过程 | 执行方式                | 负责工作                         | 工作特点         |
| -------- | ----------------------- | -------------------------------- | ---------------- |
| 硬中断   | 打断 CPU 正在执⾏的任务 | 跟硬件紧密相关或者时间敏感的事情 | 耗时短，快速执⾏ |
| 软中断         |     内核线程   | 延迟处理上半部未完成的⼯作    |     耗时⽐较⻓             |

⼀些内核⾃定义事件也属于软中断，⽐如内核调度等、RCU 锁（内核⾥常⽤的⼀种锁）等。



## 浮点数

### 负数补码
十进制整数与二进制的转换
除2取余
![](Pasted%20image%2020230719101457.png)
负数
之所以采用补码的方式来表示负数，是因为如果用符号位来表示负数，当-2+1时得到的却是-3
10000000000000000000000000000010+
00000000000000000000000000000001=
10000000000000000000000000000011
如果用补码表示负数，即负数=正数取反+1，那么就得到了-1
11111111111111111111111111111110+
00000000000000000000000000000001=
11111111111111111111111111111111

浮点数

十进制小数与二进制的转换
乘2取整
例如0.625
0.625x2=1.25 - 1
0.25x2=0.5 - 0
0.5x2=1.0 - 1
.101
但对于0.1
0.1x2=0.2
0.2x2=0.4
0.4x2=0.8
0.8x2=1.6
...
0.1的二进制表示是无限循环，因此计算机表示会有精度损失

计算机中的存储也不是十进制小数那样存储，例如8.625 - 1000.101
可以表示为1.000101 x 2^3，类似于科学记数法，且是规范化的科学计数法，即1.xxxx 
其中000101称为尾数
3称为指数
浮点数在计算机的1存储格式为：
符号位-指数位-尾数
- 符号位：表示数字是正数还是负数，为 0 表示正数，为 1 表示负数；
- 指数位：指定了⼩数点在数据中的位置，指数可以是负数，也可以是正数，指数位的⻓度越⻓则数值的表达范围就越⼤；
- 尾数位：⼩数点右侧的数字，也就是⼩数部分，⽐如⼆进制 1.0011 x 2^(-2)，尾数部分就是 0011，⽽且尾数的⻓度决定了这个数的精度，因此如果要表示精度更⾼的⼩数，则就要提⾼尾数位的⻓度；
尾数决定精度，指数决定范围

32位浮点数 float和64位浮点数double的尾数位同时都带有⼀个固定隐含位，因此double 有 53 个⼆进制有效位，float 有 24 个⼆进制有效位。
| 浮点数 | 位数 | 符号位 | 指数位 | 尾数位 |
| ------ | ---- | ------ | ------ | ------ |
| float  | 32bit   | 0/1    | 8bit   | 23bit  |
| double | 63bit   | 0/1    | 11bit  | 52bit       |

它们的精度在⼗进制中分别是 log10(2^53) 约等于 15.95 位小数和 log10(2^24) 约等于 7.22 位小数。即 double 的有效数字是 15~16 位，float 的有效数字是 7~8 位，这些是有效位是包含整数部分和⼩数部分。
例子：
10.625
- 整数位转为二进制1010.101，整体位移位1.010101
- 正整数符号位为0
- 指数位就是移动的位数，向右移动就是+3，向左移动就是-3
- 移动的位数需要加上偏移量127，即127+3=130 -> 100000010
- 1.010101就是尾数位，尾数是23位的，因此要在后面补上0：010101000000000000000
![](Pasted%20image%2020230719104248.png)

指数可能是正数，也可能是负数，即指数是有符号的整数，⽽有符号整数的计算是⽐⽆符号整数麻烦的，所以为了减少不必要的麻烦，在实际存储指数的时候，需要把指数转换成⽆符号整数。
float指数位为8，即-126~127，因此加上127可以使负数的指数变为正数

移动后的⼩数点左侧的有效位（即 1）消失了，它并没有存储到 float ⾥。因为 IEEE 标准规定，⼆进制浮点数的⼩数点左侧只能有 1 位，并且还只能是 1。

$$
-1^{\text{sign}} \times (1+\text{mantissa}) \times 2^{\text{index}-127}
$$


# 操作系统结构

## linux 内核 vs Windows内核

现代操作系统，内核⼀般会提供 4 个基本能⼒：

- 管理进程、线程，决定哪个进程、线程使⽤ CPU，也就是进程调度的能⼒；
- 管理内存，决定内存的分配和回收，也就是内存管理的能⼒；
- 管理硬件设备，为进程与硬件设备之间提供通信能⼒，也就是硬件通信能⼒；
- 提供系统调⽤，如果应⽤程序要运⾏更⾼权限运⾏的服务，那么就需要有系统调⽤，它是⽤户程序与操作系统之间的接⼝。


内核具有很⾼的权限，可以控制 cpu、内存、硬盘等硬件，⽽应⽤程序具有的权限很⼩，因此⼤多数操作系统，把内存分成了两个区域：

- 内核空间，这个内存空间只有内核程序可以访问；
- ⽤户空间，这个内存空间专⻔给应⽤程序使⽤；




![](Pasted%20image%2020230719142148.png)
内核程序执⾏在内核态，⽤户程序执⾏在⽤户态。
- 当应⽤程序使⽤系统调⽤时，CPU 会中断当前在执⾏的⽤户程序，转⽽跳转到中断处理程序。
- 内核处理完后，主动触发中断，把 CPU 执⾏权限交回给⽤户程序，回到⽤户态继续⼯作。



# 内存管理
## 虚拟内存

单⽚机是没有操作系统的，单⽚机的 CPU 是直接操作内存的「物理地址」。

把进程所使⽤的地址「隔离」开来，即让操作系统为每个进程分配独⽴的⼀套「虚拟地址」。操作系统会提供⼀种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。

进程持有的虚拟地址会通过 CPU 芯⽚中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存。

![](Pasted%20image%2020230719143259.png)

### 内存分段

程序是由若⼲个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就⽤分段（Segmentation）的形式把这些段分离出来。

分段机制下的虚拟地址由两部分组成，段选择⼦和段内偏移量。
- 虚拟地址由段选择⼦和段内偏移量组成
- 段选择⼦包含了段号等，通过段号可以在段表中查到段内描述符
- 段内描述符记录了段基地址，段界限等
- 段内偏移量如果不超过段界限，从段基地址加上段内偏移量则可以得到物理内存

![](Pasted%20image%2020230719143344.png)

虚拟地址是通过段表与物理地址进⾏映射的，分段机制会把程序的虚拟地址分成 4 个段
每个段在段表中有⼀个项，在这⼀项找到段的基地址。
例如，段3偏移量500的虚拟地址，可得出物理地址为基地址7000+偏移量5000=7500
![](Pasted%20image%2020230719145300.png)

分段的不足是：
产⽣了多个不连续的⼩物理内存，导致新的程序⽆法被装载
我们可以把碎片之间的程序占用的内存写到硬盘上，然后再从硬盘上读回来到内存⾥。
对于多进程的系统来说，⽤分段的⽅式，内存碎⽚是很容易产⽣的，产⽣了内存碎⽚。wap 内存区域会产⽣性能瓶颈，因为硬盘的访问速度要⽐内存慢太多了。


### 内存分页
分⻚是把整个虚拟和物理内存空间切成⼀段段固定尺⼨的⼤⼩。虚拟地址与物理地址之间通过⻚表来映射。
⻚表是存储在内存⾥的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的⼯作。


⽽当进程访问的虚拟地址在⻚表中查不到时，系统会产⽣⼀个缺⻚异常，进⼊系统内核空间分配物理内存、更新进程⻚表，最后再返回⽤户空间，恢复进程的运⾏。（缺页中断）


分页的内存空间都是预先划分好的，也就不会像分段会产⽣间隙⾮常⼩的内存
采⽤了分⻚，那么释放的内存都是以⻚为单位释放的，也就不会产⽣⽆法给进程使⽤的⼩内存。
如果内存空间不够，操作系统会把其他正在运⾏的进程中的「最近没被使⽤」的内存⻚⾯给释放掉，暂时写在硬盘上，称为换出。⼀旦需要的时候，再加载进来，称为换⼊。


![](Pasted%20image%2020230719150322.png)

我们不再需要⼀次性都把程序加载到物理内存中，可在程序运⾏中，只当需要⽤到对应虚拟内存⻚⾥⾯的指令和数据时，再加载到物理内存⾥⾯去。
在分⻚机制下
- 虚拟地址分为两部分，⻚号和⻚内偏移。
- 页号是页表的索引
- 页表每一项存的是虚拟内存页号对应的物理内存的页号
- 根据物理页号查到物理内存页的地址，加上页内偏移就得到了物理内存地址


![](Pasted%20image%2020230719150450.png)



简单的分⻚有空间上的缺陷。
在 32 位的环境下，虚拟地址空间共有 4GB，假设⼀个⻚的⼤⼩是 4KB（2^12），那么就需要⼤约 100 万（2^20） 个⻚，每个「⻚表项」需要 4 个字节⼤⼩来存储，那么整个 4GB 空间的映射就需要有 4MB的内存来存储⻚表。

每个进程都是有⾃⼰的虚拟地址空间，即自己的⻚表。

100 个进程的话，就需要 400MB 的内存来存储⻚表，这是⾮常⼤的内存了


因此需要多级⻚表
把这个 100 多万个「⻚表项」的单级⻚表再分⻚，将⻚表（⼀级⻚表）分为 1024 个⻚表（⼆级⻚表），每个表（⼆级⻚表）中包含 1024 个「⻚表项」，形成⼆级分⻚。
分了⼆级表，映射 4GB 地址空间就需要 4KB（⼀级⻚表）+ 4MB（⼆级⻚表）的内存。
 4KB的⼀级⻚表就可以覆盖整个 4GB 虚拟地址空间，如果某个⼀级⻚表的⻚表项没有被⽤到，也就不需要创建这个⻚表项对应的⼆级⻚表了，即可以在需要时才创建⼆级⻚表。
页表一定要能覆盖索引内存，不分级页表必须要以4MB的大小去完全覆盖，而分级的页表全覆盖的成本是4KB，对于没有分配的内存无需创建二级页表，对于已分配的内存在物理内存紧张的情况下，操作系统会将⻚⾯换出到硬盘。



![](Pasted%20image%2020230719150939.png)


对于 64 位的系统，两级分⻚肯定不够了，就变成了四级⽬录，分别是：
全局⻚⽬录项 PGD（Page Global Directory）；
上层⻚⽬录项 PUD（Page Upper Directory）；
中间⻚⽬录项 PMD（Page Middle Directory）；
⻚表项 PTE（Page Table Entry）；

多级⻚表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了⼏道转换的⼯序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。

![](Pasted%20image%2020230719151536.png)


程序是有局部性的，即在⼀段时间内，整个程序的执⾏仅限于程序中的某⼀部分。相应地，执⾏所访问的存储空间也局限于某个内存区域。可以把最常访问的⼏个⻚表项存储到访问速度更快的硬件，在 CPU 芯⽚中，加⼊了⼀个专⻔存放程序最常访问的⻚表项的 Cache，这个 Cache 就是 TLB ，通常称为⻚表缓存、转址旁路缓存、快表等。
有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的⻚表。

### 段页式内存管理
段⻚式内存管理实现的⽅式：
- 将程序划分为多个有逻辑意义的段
- 把每个段划分为多个⻚，对分段划分出来的连续空间，再划分固定⼤⼩的⻚；
这样，地址结构就由段号、段内⻚号和⻚内位移三部分组成。
段⻚式地址变换中要得到物理地址须经过三次内存访问：
第⼀次访问段表，得到⻚表起始地址；
第⼆次访问⻚表，得到物理⻚号；
第三次将物理⻚号与⻚内位移组合，得到物理地址。
![](Pasted%20image%2020230719151811.png)


Intel

逻辑地址->虚拟地址->物理地址

- 程序所使⽤的地址，通常是没被段式内存管理映射的地址，称为逻辑地址；
- 通过段式内存管理映射的地址，称为线性地址，也叫虚拟地址，是「⻚式内存管理」转换前的地址。

Linux 内核所采取的办法是使段式映射的过程实际上不起什么作⽤。
Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间，也就是所有的段的起始地址都是⼀样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应⽤程序代码，所⾯对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被⽤于访问控制和内存保护。

在 Linux 操作系统中，虚拟地址空间的内部⼜被分为内核空间和⽤户空间两部分，不同位数的系统，地址空间的范围也不同。⽐如最常⻅的 32 位和 64 位系统，如下所示：

![](Pasted%20image%2020230719152207.png)

进程在⽤户态时，只能访问⽤户空间内存；
只有进⼊内核态后，才可以访问内核空间的内存；

虽然每个进程都各⾃有独⽴的虚拟内存，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。这样，进程切换到内核态后，就可以很⽅便地访问内核空间内存。

⽤户空间内存，从低到⾼分别是 7 种不同的内存段：
| 地址        | 空间              |
| ----------- | ----------------- |
| 0xFFFFFFFFF | 内核空间          |
| 0xC0000000  | 栈                |
|             | ↓     ↑           |
|             | 文件映射          |
|             | ↑                 |
|             | 堆                |
|             | 未初始化数据.bass |
|             | 已初始化数据.data |
|             | 程序文件.text     |
| 0x00000000  | 预留              |

程序⽂件段，包括⼆进制可执⾏代码；
已初始化数据段，包括静态常量；
未初始化数据段，包括未初始化的静态变量；
堆段，包括动态分配的内存，从低地址开始向上增⻓；
⽂件映射段，包括动态库、共享内存等，从低地址开始向上增⻓（跟硬件和内核版本有关）；
栈段，包括局部变量和函数调⽤的上下⽂等。栈的⼤⼩是固定的，⼀般是 8 MB 。当然系统也提供了参数，以便我们⾃定义⼤⼩；

堆和⽂件映射段的内存是动态分配的。使⽤ C 标准库的 malloc() 或者mmap() ，就可以分别在堆和⽂件映射段动态分配内存。

# 进程与线程

## 进程
运⾏中的程序，就被称为「进程」


有⼀个会读取硬盘⽂件数据的程序被执⾏了，当运⾏到读取⽂件的指令时，就会去从硬盘读取数据，但是硬盘的读写速度是⾮常慢的，CPU 不需要阻塞等待数据的返回，⽽是去执⾏另外的进程。
当硬盘数据返回时，CPU 会收到个中断，于是 CPU 再继续运⾏这个进程。
对于⼀个⽀持多进程的系统，CPU 会从⼀个进程快速切换⾄另⼀个进程，其间每个进程各运⾏⼏⼗或⼏百个毫秒。
虽然单核的 CPU 在某⼀个瞬间，只能运⾏⼀个进程。但在 1 秒钟期间，它可能会运⾏多个进程，这样产⽣并⾏的错觉，实际上这是并发。


![](Pasted%20image%2020230719164139.png)

CPU 可以从⼀个进程切换到另外⼀个进程，在切换前必须要记录当前进程中运⾏的状态信息，以备下次切换回来的时候可以恢复执⾏。可以发现进程有着「运⾏ - 暂停 - 运⾏」的活动规律。
⼀个进程并不是⾃始⾄终连续不停地运⾏的，它与并发执⾏中的其他进程的执⾏是相互制约的。

如果有⼤量处于阻塞状态的进程，进程可能会占⽤着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占⽤着物理内存就⼀种浪费物理内存的⾏为。

在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运⾏的时候，再从硬盘换⼊到物理内存。
挂起状态描述进程没有占⽤实际的物理内存空间的情况，可以分为两种
阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；
就绪挂起状态：进程在外存（硬盘），但只要进⼊内存，即刻⽴刻运⾏；
![](Pasted%20image%2020230719164537.png)
导致进程挂起的原因不只是因为进程所使⽤的内存空间不在物理内存
通过 sleep 让进程间歇性挂起，其⼯作原理是设置⼀个定时器，到期后唤醒进程。
⽤户希望挂起⼀个程序的执⾏，⽐如在 Linux 中⽤ Ctrl+Z 挂起进程；



### 进程的控制结构
在操作系统中，是⽤进程控制块PCB数据结构来描述进程的。

- 进程描述信息：
	- 进程标识符：标识各个进程，每个进程都有⼀个并且唯⼀的标识符；
	- ⽤户标识符：进程归属的⽤户，⽤户标识符主要为共享和保护服务；
- 进程控制和管理信息：
	- 进程当前状态，如 new、ready、running、waiting 或 blocked 等；
	- 进程优先级：进程抢占 CPU 时的优先级；
- 资源分配清单：
	- 有关内存地址空间或虚拟地址空间的信息，所打开⽂件的列表和所使⽤的 I/O 设备信息。
- CPU 相关信息：
	- CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执⾏时，能从断点处继续执⾏。

简单来说就是
1.身份，属于哪个用户，以及自己的id
2.状态，进程的状态和优先级
3.财产，持有的内存地址、打开的文件、使用的IO设备
4.存档，当被切换时，把自己的当前的信息记下来，切换回来时再继续执行

PCB通常是通过链表的⽅式进⾏组织，把具有相同状态的进程链在⼀起，组成各种队列。

- 所有处于就绪状态的进程链为就绪队列；
- 所有因等待某事件⽽处于等待状态的进程链为阻塞队列；

对于运⾏队列在单核 CPU 系统中则只有⼀个运⾏指针了，因为单核 CPU 在某个时间，只能运⾏⼀个程序。

![](Pasted%20image%2020230719165148.png)


除了链接的组织⽅式，还有索引⽅式
将同⼀状态的进程组织在⼀个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。⼀般会选择链表，因为可能⾯临进程创建，销毁等调度导致进程状态发⽣变化，所以链表能够更加灵活的插⼊和删除。

### 进程的控制
**创建**
操作系统允许⼀个进程创建另⼀个进程，⽽且允许⼦进程继承⽗进程所拥有的资源

当⼦进程被终⽌时，其在⽗进程处继承的资源应当还给⽗进程。同时，终⽌⽗进程时同时也会终⽌其所有的⼦进程。

子死父继，父死子亡
创建进程的过程如下：
- 分配⼀个唯⼀的进程标识号，并申请⼀个空⽩的 PCB，PCB 是有限的，若申请失败则创建失败；
- 分配资源，此处如果资源不⾜，进程就会进⼊等待状态，以等待资源；
- 初始化 PCB；
- 如果进程的调度队列能够接纳新进程，那就将进程插⼊到就绪队列，等待被调度运⾏；


**终⽌**
终⽌进程的过程如下：
- 查找需要终⽌的进程的 PCB；
- 如果处于执⾏状态，则⽴即终⽌该进程的执⾏，然后将 CPU 资源分配给其他进程；
- 如果其还有⼦进程，则应将其所有⼦进程终⽌；
- 将该进程所拥有的全部资源都归还给⽗进程或操作系统；
- 将其从 PCB 所在队列中删除；


**阻塞**
当进程需要等待某⼀事件完成时，它可以调⽤阻塞语句把⾃⼰阻塞等待。⽽⼀旦被阻塞等待，它只能由另⼀个进程唤醒。
阻塞进程的过程如下：
- 找到将要被阻塞进程标识号对应的 PCB；
- 如果该进程为运⾏状态，则保护其现场，将其状态转为阻塞状态，停⽌运⾏；
- 将该 PCB 插⼊到阻塞队列中去；

唤醒
进程由「运⾏」转变为「阻塞」状态是由于进程必须等待某⼀事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒⾃⼰的。

如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程⽤唤醒语句叫醒它。
唤醒进程的过程如下：
- 在该事件的阻塞队列中找到相应进程的 PCB；
- 将其从阻塞队列中移出，并置其状态为就绪状态；
- 把该 PCB 插⼊到就绪队列中，等待调度程序调度；

### 进程的上下⽂切换
各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执⾏，那么这个⼀个进程切换到另⼀个进程运⾏，称为进程的上下⽂切换。

任务是交给 CPU 运⾏的，那么在每个任务运⾏前，CPU 需要知道任务从哪⾥加载，⼜从哪⾥开始运⾏。
所以，操作系统需要事先帮 CPU 设置好 CPU 寄存器和程序计数器。

程序计数器则是⽤来存储 CPU 正在执⾏的指令位置、或者即将执⾏的下⼀条指令位置。

CPU 寄存器和程序计数是 CPU 在运⾏任何任务前，所必须依赖的环境，这些环境就叫做 CPU上下⽂。

CPU 上下⽂切换
CPU 上下⽂切换就是先把前⼀个任务的 CPU 上下⽂（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下⽂到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运⾏新任务。
系统内核会存储保持下来的上下⽂信息，当此任务再次被分配给 CPU 运⾏时，CPU 会重新加载这些上下⽂，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运⾏。
根据任务的不同，把 CPU 上下⽂切换分成：进程上下⽂切换、线程上下⽂切换和中断上下⽂切换。

进程的上下⽂切换
进程是由内核管理和调度的，所以进程的切换只能发⽣在内核态。进程的上下⽂切换不仅包含了虚拟内存、栈、全局变量等⽤户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。
把交换的信息保存在进程的 PCB，当要运⾏另外⼀个进程的时候，我们需要从这个进程的 PCB取出上下⽂，然后恢复到 CPU 中，这使得这个进程可以继续执⾏，

![](Pasted%20image%2020230719194351.png)

CPU 时间被划分为⼀段段的时间⽚，这些时间⽚再被轮流分配给各个进程。这样，当某个进程的时间⽚耗尽了，进程就从运⾏状态变为就绪状态，系统从就绪队列选择另外⼀个进程运⾏；

进程在系统资源不⾜（⽐如内存不⾜）时，要等到资源满⾜后才可以运⾏，这个时候进程也会被挂起，并由系统调度其他进程运⾏；
当进程通过睡眠函数 sleep 这样的⽅法将⾃⼰主动挂起时，⾃然也会重新调度；
当有优先级更⾼的进程运⾏时，为了保证⾼优先级进程的运⾏，当前进程会被挂起，由⾼优先级进程来运⾏；
发⽣硬件中断时，CPU 上的进程会被中断挂起，转⽽执⾏内核中的中断服务程序；


在早期的操作系统中都是以进程作为独⽴运⾏的基本单位
线程之间可以并发运⾏且共享相同的地址空间。
线程是进程当中的⼀条执⾏流程。
同⼀个进程内多个线程之间可以共享代码段、数据段、打开的⽂件等资源，但每个线程各⾃都有⼀套独⽴
的寄存器和栈，这样可以确保线程的控制流是相对独⽴的。
![](Pasted%20image%2020230719201339.png)
⼀个进程中可以同时存在多个线程；
各个线程之间可以并发执⾏；
各个线程之间可以共享地址空间和⽂件等资源；

当进程中的⼀个线程崩溃时，会导致其所属进程的所有线程崩溃。

### 线程与进程的⽐较
线程与进程的⽐较如下：
- 进程是资源（包括内存、打开的⽂件等）分配的单位，线程是 CPU 调度的单位；
- 进程拥有⼀个完整的资源平台，⽽线程只独享必不可少的资源，如寄存器和栈；
- 线程同样具有就绪、阻塞、执⾏三种基本状态，同样具有状态之间的转换关系；
- 线程能减少并发执⾏的时间和空间开销；

对于，线程相⽐进程能减少开销，体现在：
- 线程的创建时间⽐进程快，因为进程在创建的过程中，还需要资源管理信息，⽐如内存管理信息、⽂件管理信息，⽽线程在创建的过程中，不会涉及这些资源管理信息，⽽是共享它们；
- 线程的终⽌时间⽐进程快，因为线程释放的资源相⽐进程少很多；
- 同⼀个进程内的线程切换⽐进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同⼀个进程的线程都具有同⼀个⻚表，那么在切换的时候不需要切换⻚表。⽽对于进程之间的切换，切换的时候要把⻚表给切换掉，⽽⻚表的切换过程开销是⽐较⼤的；
- 由于同⼀进程的各线程间共享内存和⽂件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更⾼了；

线程是调度的基本单位，⽽进程则是资源拥有的基本单位。
当进程只有⼀个线程时，可以认为进程就等于线程；
当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下⽂切换时是不需要修改的；

线程也有⾃⼰的私有数据，⽐如栈和寄存器等，这些在上下⽂切换时也是需要保存的。

当两个线程不是属于同⼀个进程，则切换的过程就跟进程上下⽂切换⼀样；
当两个线程是属于同⼀个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；

### 线程的实现
- ⽤户线程（User Thread）：在⽤户空间实现的线程，不是由内核管理的线程，是由⽤户态的线程库来完成线程的管理；
- 内核线程（Kernel Thread）：在内核中实现的线程，是由内核管理的线程；
- 轻量级进程（LightWeight Process）：在内核中来⽀持⽤户线程；

#### ⽤户线程
⽤户线程是基于⽤户态的线程管理库来实现的，那么线程控制块（Thread Control Block, TCB） 也是在库⾥⾯来实现的，对于操作系统⽽⾔是看不到这个 TCB 的，它只能看到整个进程的 PCB。

⽤户线程的整个线程管理和调度，操作系统是不直接参与的，⽽是由⽤户级线程库函数来完成线程的管理，包括线程的创建、终⽌、同步和调度等。

⽤户级线程的模型是多对⼀的关系，即多个⽤户线程对应同⼀个内核线程。
每个进程都需要有它私有的线程控制块（TCB）列表，⽤来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由⽤户级线程库函数来维护，可⽤于不⽀持线程技术的操作系统；
⽤户线程的切换也是由线程库函数来完成的，⽆需⽤户态与内核态的切换，所以速度特别快；

![](Pasted%20image%2020230719202926.png)


由于操作系统不参与线程的调度，如果⼀个线程发起了系统调⽤⽽阻塞，那进程所包含的⽤户线程都不能执⾏了
当⼀个线程开始运⾏后，除⾮它主动地交出 CPU 的使⽤权，否则它所在的进程当中的其他线程⽆法运⾏，因为⽤户态的线程没法打断当前运⾏中的线程，它没有这个特权，只有操作系统才有，但是⽤户线程不是由操作系统管理的。
由于时间⽚分配给进程，故与其他进程⽐，在多线程执⾏时，每个线程得到的时间⽚较少，执⾏会⽐较慢；
#### 内核线程
内核线程是由操作系统管理的，线程对应的 TCB ⾃然是放在操作系统⾥的，这样线程的创建、终⽌和管理都是由操作系统负责。
内核线程的模型是⼀对⼀的关系，即⼀个⽤户线程对应⼀个内核线程。

在⼀个进程当中，如果某个内核线程发起系统调⽤⽽被阻塞，并不会影响其他内核线程的运⾏；
分配给线程，多线程的进程获得更多的 CPU 运⾏时间；

在⽀持内核线程的操作系统中，由内核来维护进程和线程的上下⽂信息，如 PCB 和 TCB；
线程的创建、终⽌和切换都是通过系统调⽤的⽅式来进⾏，因此对于系统来说，系统开销⽐较⼤；

![](Pasted%20image%2020230719203151.png)



轻量级进程 LWP 是内核⽀持的⽤户线程，⼀个进程可有⼀个或多个 LWP，每个 LWP 是跟内核线程⼀对⼀映射的，是 LWP 都是由⼀个内核线程⽀持。
LWP 只能由内核管理并像普通进程⼀样被调度，Linux 内核是⽀持 LWP 的典型例⼦

LWP与普通进程的区别也在于它只有⼀个最⼩的执⾏上下⽂和调度程序所需的统计信息。
⼀个进程代表程序的⼀个实例，⽽ LWP 代表程序的执⾏线程，因为⼀个执⾏线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。


在 LWP 之上也是可以使⽤⽤户线程的，那么 LWP 与⽤户线程的对应关系就有三种：
1 : 1 ，即⼀个 LWP 对应 ⼀个⽤户线程；
N : 1 ，即⼀个 LWP 对应多个⽤户线程；
M : N ，即多个 LMP 对应多个⽤户线程；


调度
⼀旦操作系统把进程切换到运⾏状态，也就意味着该进程占⽤着 CPU 在执⾏，但是当操作系统把进程切换到其他状态时，那就不能在 CPU 中执⾏了，于是操作系统会选择下⼀个要运⾏的进程。
选择⼀个进程运⾏这⼀功能是在操作系统中完成的，通常称为调度程序（scheduler）。

在进程的⽣命周期中，当进程从⼀个运⾏状态到另外⼀状态变化的时候，其实会触发⼀次调度。


因为，这些状态变化的时候，操作系统需要考虑是否要让新的进程给 CPU 运⾏，或者是否让当前进程从CPU 上退出来⽽换另⼀个进程运⾏。
⾮抢占式调度算法
挑选⼀个进程，然后让该进程运⾏直到被阻塞，或者直到该进程退出，才会调⽤另外⼀个进程，也就是说不会理时钟中断这个事情。

抢占式调度算法
挑选⼀个进程，然后让该进程只运⾏某段时间，如果在该时段结束时，该进程仍然在运⾏时，则会把它挂起，接着调度程序从就绪队列挑选另外⼀个进程。这种抢占式调度处理，需要在时间间隔的末端发⽣时钟中断，以便把 CPU 控制返回给调度程序进⾏调度，也就是常说的时间⽚机制。


## 进程间通信

管道


`$ ps auxf | grep mysql`
命令⾏⾥的「 | 」竖线就是⼀个管道，它的功能是将前⼀个命令（ ps auxf ）的输出，作为后⼀个命令（ grep mysql ）的输⼊。管道传输数据是单向的，如果想相互通信，我们需要创建两个管道才⾏。管道没有名字，所以「 | 」表示的管道称为匿名管道，⽤完了就销毁。
命名管道，也被叫做 FIFO ，因为数据是先进先出的传输⽅式。
在使⽤命名管道前，先需要通过 mkfifo 命令来创建，并且指定管道名字：
`$ mkfifo myPipe`
管道这种通信⽅式效率低，不适合进程间频繁地交换数据。它的好处，⾃然就是简单，同时也我们很容易得知管道⾥的数据已经被另⼀个进程读取了。


`int pipe(int fd[2])`⾥表示创建⼀个匿名管道，并返回了两个描述符，⼀个是管道的读取端描述符 fd[0] ，另⼀个是管道的写⼊端描述符 fd[1] 。
![](Pasted%20image%2020230719204947.png)

所谓的管道，就是内核⾥⾯的⼀串缓存。
从管道的⼀段写⼊的数据，实际上是缓存在内核中的.
另⼀端读取，也就是从内核中读取这段数据。
另外，管道传输的数据是⽆格式的流且⼤⼩受限。

两个描述符都是在⼀个进程⾥⾯，并没有起到进程间通信的作⽤，此时需要使⽤ fork 创建⼦进程，创建的⼦进程会复制⽗进程的⽂件描述符，两个进程就可以通过各⾃的 fd 写⼊和读取同⼀个管道⽂件实现跨进程通信

![](Pasted%20image%2020230719205141.png)



⽗进程和⼦进程都可以同时写⼊，也都可以读出。为了避免这种情况，通常的做法是：
⽗进程关闭读取的 fd[0]，只保留写⼊的 fd[1]；
⼦进程关闭写⼊的 fd[1]，只保留读取的 fd[0]；

所以说如果需要双向通信，则应该创建两个管道。

在 shell ⾥⾯执⾏ A | B 命令的时候，A 进程和 B 进程都是 shell 创建出来的⼦进程，A 和 B 之间不存在⽗⼦关系，它俩的⽗进程都是 shell。在 shell ⾥通过「 | 」匿名管道将多个命令连接在⼀起，实际上也就是创建了多个⼦进程
![](Pasted%20image%2020230719205311.png)
对于匿名管道，它的通信范围是存在⽗⼦关系的进程，管道没有实体，也就是没有管道⽂件，只能通过 fork 来复制⽗进程 fd ⽂件描述符，来达到通信的⽬的。

对于命名管道，它可以在不相关的进程间也能相互通信。因为命令管道，提前创建了⼀个类型为管道的设备⽂件，在进程⾥只要使⽤这个设备⽂件，就可以相互通信。不管是匿名管道还是命名管道，进程写⼊的数据都是缓存在内核中。另⼀个进程读取数据时候⾃然也是从内核中获取，同时通信数据都遵循先进先出原则，不⽀持 lseek 之类的⽂件定位操作。


消息队列
消息队列的通信模式就可以解决进程间频繁地交换数据。
A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。

消息队列是保存在内核中的消息链表
在发送数据时，会分成⼀个⼀个独⽴的数据单元，也就是消息体（数据块）
消息体是⽤户⾃定义的数据类型，消息的发送⽅和接收⽅要约定好消息体的数据类型，
所以每个消息体都是固定⼤⼩的存储块，不像管道是⽆格式的字节流数据。
如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。

消息队列⽣命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会⼀直存在。
的匿名管道的⽣命周期，是随进程的创建⽽建⽴，随进程的结束⽽销毁

两个进程之间的通信就像平时发邮件⼀样，你来⼀封，我回⼀封

⼀是通信不及时，⼆是附件也有⼤⼩限制
消息队列不适合⽐较⼤数据的传输，因为在内核中每个消息体都有⼀个最⼤⻓度的限制

消息队列通信过程中，存在⽤户态与内核态之间的数据拷⻉开销。进程写⼊数据到内核中的消息队列
时，会发⽣从⽤户态拷⻉数据到内核态的过程。同理另⼀进程读取内核中的消息数据时，会发⽣从内核态
拷⻉数据到⽤户态的过程。

共享内存
消息队列的读取和写⼊的过程，都会有发⽣⽤户态与内核态之间的消息拷⻉过程。那共享内存的⽅式，就很好的解决了这⼀问题。

内存管理，采⽤的是虚拟内存技术，也就是每个进程都有⾃⼰独⽴的虚拟内存空间
不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和 进程 B 的虚拟地址是⼀样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。

共享内存的机制，就是拿出⼀块虚拟地址空间来，映射到相同的物理内存中
![](Pasted%20image%2020230719205801.png)
如果多个进程同时修改同⼀个共享内存，很有可能就冲突了。例如两个进程都同时写⼀个地址，那先写的那个进程会发现内容被别⼈覆盖了。
为了防⽌多进程竞争共享资源，⽽造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被⼀个进程访问。正好，信号量就实现了这⼀保护机制。

信号量
信号量其实是⼀个整型的计数器，主要⽤于实现进程间的互斥与同步，⽽不是⽤于缓存进程间通信的数据。

信号量表示资源的数量，控制信号量的⽅式有两种原⼦操作：
- ⼀个是 P 操作，这个操作会把信号量减去 1，相减后如果信号量 < 0，则表明资源已被占⽤，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使⽤，进程可正常继续执⾏。
- 另⼀个是 V 操作，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运⾏；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；

P 操作是⽤在进⼊共享资源之前，V 操作是⽤在离开共享资源之后，这两个操作是必须成对出现的。


- 初始化信号量为 1 。
- 进程 A 在访问共享内存前，先执⾏了 P 操作
- 由于信号量的初始值为 1，故在进程 A 执⾏ P 操作后信号量变为 0，表示共享资源可⽤，于是进程 A 就可以访问共享内存
- 此时，进程 B 也想访问共享内存，执⾏了 P 操作，结果信号量变为了 -1，意味着临界资源已被占⽤，因此进程 B 被阻塞
- 进程 A 访问完共享内存，才会执⾏ V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程B
- 进程 B 可以访问共享内存，最后完成共享内存的访问后执⾏ V 操作，使信号量恢复到初始值 1。
信号初始化为 1 ，就代表着是互斥信号量，它可以保证共享内存在任何时刻只有⼀个进程在访
问


![](Pasted%20image%2020230719205957.png)

在多进程⾥，每个进程并不⼀定是顺序执⾏的，它们基本是以各⾃独⽴的、不可预知的速度向前推

进程 A 是负责⽣产数据，⽽进程 B 是负责读取数据
进程 A 先⽣产了数据，进程 B 才能读取到数据，所以执⾏是有前后顺序的。

- 初始化信号量为 0 。
- 进程 B ⽐进程 A 先执⾏了，那么执⾏到 P 操作时，由于信号量初始值为 0，信号量会变为-1，表示进程 A 还没⽣产数据，于是进程 B 就阻塞等待；
- 当进程 A ⽣产完数据后，执⾏了 V 操作，就会使得信号量变为 0 就会唤醒阻塞在 P 操作的进程 B；
- 进程 B 被唤醒后，意味着进程 A 已经⽣产了数据，于是进程 B 就可以正常读取数据了。

信号初始化为 0 ，就代表着是同步信号量，它可以保证进程 A 应在进程 B 之前执⾏。

![](Pasted%20image%2020230719210311.png)
信号

对于异常情况下的⼯作模式，就需要⽤「信号」的⽅式来通知进程。
信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。

信号是进程间通信机制中唯⼀的异步通信机制，因为可以在任何时候发送信号给某⼀进程，⼀旦有信号产⽣，我们就有下⾯这⼏种，⽤户进程对信号的处理⽅式。

1.执⾏默认操作。Linux 对每种信号都规定了默认操作
2.捕捉信号。我们可以为信号定义⼀个信号处理函数。当信号发⽣时，我们就执⾏相应的信号处理函数。
3.忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。

Socket
跨⽹络与不同主机上的进程之间通信，就需要 Socket 通信了。Socket 通信不仅可以跨⽹络与不同主机的进程间通信，还可以在同主机上进程间通信。

线程通信间的⽅式
同个进程下的线程之间都是共享进程的资源，只要是共享变量都可以做到线程间通信，⽐如全局变量，信号量也同样可以在线程间实现互斥与同步：
互斥的⽅式，可保证任意时刻只有⼀个线程访问共享资源；
同步的⽅式，可保证线程 A 应在线程 B 之前执⾏；


## 多线程同步
线程是调度的基本单位，进程则是资源分配的基本单位。

线程之间是可以共享进程的资源，⽐如代码段、堆空间、数据段、打开的⽂件等资源，但每个线程都有⾃⼰独⽴的栈空间。

多个线程如果竞争共享资源，如果不采取有效的措施，则会造成共享数据的混乱。

i++的汇编指令执⾏过程
假设 i 此时是 50 
- 线程 1 进⼊代码区域，将 i 值从内存加载到寄存器中
- 线程 1 将寄存器中的 i 值 + 1 ，寄存器中 i 值=51
- 时钟中断发⽣，操作系统将当前正在运⾏的线程的状态保存到线程的线程控制块 TCB。
- 线程 2 从内存获取 i 值=50并将其放⼊到寄存器中
- 线程 2 将寄存器中的 i 值 + 1
- 线程 2 将寄存器中的 i 值=51保存到内存中 
- 上下⽂切换线程 1 恢复执⾏
- 线程 1 寄存器中 i 值=51，将值保存到内存


![](Pasted%20image%2020230719212934.png)


由于多线程执⾏操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为临界区，它是访问共享资源的代码⽚段，⼀定不能给多线程同时执⾏。

我们希望这段代码是互斥（mutualexclusion）的，也就说保证⼀个线程在临界区执⾏时，其他线程应该被阻⽌进⼊临界区。

![](Pasted%20image%2020230719213437.png)
所谓同步，就是并发进程/线程在⼀些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步

同步就好⽐：「操作 A 应在操作 B 之前执⾏」，「操作 C 必须在操作 A 和操作 B 都完成之后才能执⾏」等；
互斥就好⽐：「操作 A 和操作 B 不能在同⼀时刻执⾏」；

为了实现进程/线程间正确的协作，操作系统必须提供实现进程协作的措施和⽅法，主要的⽅法有两种：
锁：加锁、解锁操作；
信号量：P、V 操作；

### 锁
任何想进⼊临界区的线程，必须先执⾏加锁操作。若加锁操作顺利通过，则线程可进⼊临界区；在完成对临界资源的访问后再执⾏解锁操作，以释放该临界资源。
根据锁的实现不同，可以分为「忙等待锁」和「⽆忙等待锁」。

原⼦操作就是要么全部执⾏，要么都不执⾏，不能出现执⾏到⼀半的中间状态

当获取不到锁时，线程就会⼀直 wile 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为⾃旋锁。

⽆等待锁顾明思议就是获取不到锁的时候，不⽤⾃旋。
既然不想⾃旋，那当没获取到锁的时候，就把当前线程放⼊到锁的等待队列，然后执⾏调度程序，把 CPU让给其他线程执⾏。






























































