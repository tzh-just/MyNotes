PBR 光照计算通常需要 position、normal、albedo、 AO，roughness，metallic 和 emissive 等参数。前向渲染是 fragment shader 中对计算 frag 与所有光源的光照。而延迟渲染利用 Mutiple Render Targets (MRT) 技术，将这些信息一次性渲染到多个 RenderTexture 中。

**第一个 Pass**
采样 PBR 材质的各种纹理贴图，然后在片元着色器中将计算光照相关的数据编码到 Render Texture，如基本颜色、金属度、世界空间法线、自发光项、粗糙度和 AO。
```c
o.GT0 = half4(BaseColor, Metallic);
o.GT1 = half4(PackNormal2Color(N),1);
o.GT2 = half4(Emission,Roughness);
o.GT3 = half4(AO,1);
```
**第二个 Pass**
在片元着色器中将 Render Texture 中的数据取出。需要注意，法线应先解码。
```c
half3 BaseColor = tex2D(_GT0,uv).rgb;
half  Metallic  = tex2D(_GT0,uv).a;
half3 Normal    = UnpackColor2Normal(tex2D(_GT1,uv).rgb);
half3 Emission  = tex2D(_GT2,uv).rgb;
half  Roughness = tex2D(_GT2,uv).a;
half3 AO        = tex2D(_GT3,uv).rgb;
```
在延迟渲染管线中，第二个 Pass 不能像前向渲染那样在顶点着色器中输出顶点的世界空间坐标。但延迟渲染可以通过顶点在屏幕空间的 uv 坐标，加上深度缓存来反推出 NDC 坐标，再进一步地通过 NDC 坐标反推出世界空间坐标。
```c
half d = UNITY_SAMPLE_DEPTH(tex2D(_gdepth, uv));
half4 ndcPos = half4(uv*2-1,d,1);
half4 worldPos = mul(_vpMatrixInv, ndcPos);
worldPos /= worldPos.w;
```
之所以可以直接从 uv 坐标还原 NDC 坐标，这是因为对于第二个 Pass，Blit 函数的作用是绘制一个覆盖了整个屏幕的 Quad，然后调用 shader 将渲染结果写入 Render Texture 中，作为相机的渲染目标。因此 0 到 1 的 uv 坐标就是屏幕每个像素的的 NDC.Xy。
```cpp
void LightPass(ScriptableRenderContext context, Camera camera){
	CommandBuffer cmd = new CommandBuffer();
	cmd.name = "LightPass";
	Material mat = new Material(Shader.Find("JustRP/LightPass"));
	cmd.Blit(gbufferID[0], BuiltinRenderTextureType.CameraTarget, mat);
	context.ExecuteCommandBuffer(cmd);
}
```

遍历每个光源计算光照，假设有 m 个网格，n 个光源，则我们需要对 N 个网格执行第一个 Pass，对 m 个光源执行第二个 Pass。因此延迟渲染的复杂度为 $O(m+n)$。
优化方法
1. 限制 GBuffer 的 RenderTarget 的分辨率。
2. 减少 GBuffer 的数量，使用压缩算法减少字节数，合并通道。
3. 使用 RGBA 8 保存 albedo 而不是 RGBA 16 F，这样显存带宽就可以降到 4 倍。
优点
1. 光照计算复杂度从 $\text{O(M * N)}$ 减少到 $\text{O(M+N)}$，减少光照计算的开销，尤其是复杂的室内多个点光源的场景。
2. 光照计算阶段只计算看得见的像素，减轻了 overdraw 的消耗。
3. 通过 GBuffer 可以方便地实现屏幕空间算法。
缺点
1. 额外的显存开销，对移动端不友好
2. 不支持透明渲染，半透明物体需要单独使用前向渲染进行绘制。
拓展
移动端适配
1. 高端机上使用延迟，低端机上退回前向
2. 根据不同画质和性能，选择不同精度的 GBuffer，压缩存储机制等。